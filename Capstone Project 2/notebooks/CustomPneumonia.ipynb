{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"CustomPneumonia.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"Krw97nCMqJ_-","colab":{"base_uri":"https://localhost:8080/","height":161},"executionInfo":{"status":"ok","timestamp":1593608579322,"user_tz":240,"elapsed":18140,"user":{"displayName":"Robert312 SpringboardDataScience","photoUrl":"","userId":"10605656056949109058"}},"outputId":"923458ae-3b49-4d9c-af99-310a3d1d8f38"},"source":["import sys\n","import os, os.path\n","\n","sys.path.append(os.path.join(os.getcwd() ,'/modules'))\n","root_path = \"C:/git/Springboard-Public/Capstone Project 2/\"\n","IN_COLAB = 'google.colab' in sys.modules\n","if IN_COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    root_path = \"/content/drive/My Drive/Capstone Project 2/\"\n","\n","print('Current Working Dir: ', os.getcwd())\n","print('Root Path: ', root_path)\n","\n","# We need to set the working directory since we are using relative paths from various locations\n","if os.getcwd() != root_path:\n","  os.chdir(root_path)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","Current Working Dir:  /content\n","Root Path:  /content/drive/My Drive/Capstone Project 2/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"A8Bb_-Y-qKAB","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1593608586582,"user_tz":240,"elapsed":25389,"user":{"displayName":"Robert312 SpringboardDataScience","photoUrl":"","userId":"10605656056949109058"}},"outputId":"0a18eeb3-4c8b-4952-80bf-965e9c7e73eb"},"source":["import numpy as np\n","from datetime import datetime\n","from collections import defaultdict\n","import matplotlib.pyplot as plt\n","import seaborn as sns; sns.set()\n","\n","from modules.lib.ChextXRayImages import *\n","from modules.models.CustomPneumonia import CustomPneumoniaNN\n","\n","from PIL import Image\n","import copy\n","\n","import torch.optim as optim\n","import torch\n","import torch.utils.data\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision.transforms import ToTensor, ToPILImage\n","import torchvision.models as models\n","\n","from torchsummary import summary\n","\n","# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","\n","%matplotlib inline"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SBlzQJJIqKAD","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593608586583,"user_tz":240,"elapsed":25382,"user":{"displayName":"Robert312 SpringboardDataScience","photoUrl":"","userId":"10605656056949109058"}},"outputId":"aa6e57c0-e47a-4548-e676-ab588aa2f635"},"source":["force_cpu = True\n","device = torch.device('cuda' if ~force_cpu and torch.cuda.is_available() else 'cpu')\n","# Assume that we are on a CUDA machine, then this should print a CUDA device:\n","print(f'Working on device={device}')\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Working on device=cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Pihx9dmDqKAH","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1593608595264,"user_tz":240,"elapsed":34055,"user":{"displayName":"Robert312 SpringboardDataScience","photoUrl":"","userId":"10605656056949109058"}},"outputId":"3e36e4c4-2d3f-42ff-f0e7-af69f9a98ca9"},"source":["loaders = Loaders()\n","batch_size=8\n","val_percent=0.20\n","number_images = 20000\n","train_loader, val_loader = loaders.getDataTrainValidateLoaders(batch_size=batch_size, \n","                                                                        val_percent=val_percent, \n","                                                                        n_random_rows=number_images)\n","print(f'Number of Training Batches: {len(train_loader):,}')\n","print(f'Number of Validation Batches: {len(val_loader):,}')\n","print(f'Number of Training Images: {len(train_loader) * batch_size:,}')\n","print(f'Number of Validation Images: {len(val_loader) * batch_size:,}')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Number of Training Batches: 2,012\n","Number of Validation Batches: 489\n","Number of Training Images: 16,096\n","Number of Validation Images: 3,912\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oal5V5NeqKAG","colab":{"base_uri":"https://localhost:8080/","height":514},"executionInfo":{"status":"ok","timestamp":1593608605877,"user_tz":240,"elapsed":44661,"user":{"displayName":"Robert312 SpringboardDataScience","photoUrl":"","userId":"10605656056949109058"}},"outputId":"d1303695-d7e9-4383-fccf-9e32f0b48060"},"source":["net = CustomPneumoniaNN()\n","\n","net = nn.DataParallel(net)\n","net.to(device)\n","\n","summary(net, (1, 320, 320))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1        [-1, 512, 320, 320]          13,312\n","       BatchNorm2d-2        [-1, 512, 320, 320]           1,024\n","         MaxPool2d-3        [-1, 512, 160, 160]               0\n","            Conv2d-4        [-1, 256, 160, 160]       1,179,904\n","       BatchNorm2d-5        [-1, 256, 160, 160]             512\n","         MaxPool2d-6          [-1, 256, 80, 80]               0\n","            Conv2d-7           [-1, 64, 80, 80]         147,520\n","       BatchNorm2d-8           [-1, 64, 80, 80]             128\n","         MaxPool2d-9           [-1, 64, 40, 40]               0\n","           Linear-10                 [-1, 1024]     104,858,624\n","          Dropout-11                 [-1, 1024]               0\n","           Linear-12                  [-1, 512]         524,800\n","          Dropout-13                  [-1, 512]               0\n","           Linear-14                   [-1, 12]           6,156\n","CustomPneumoniaNN-15                   [-1, 12]               0\n","================================================================\n","Total params: 106,731,980\n","Trainable params: 106,731,980\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.39\n","Forward/backward pass size (MB): 1019.55\n","Params size (MB): 407.15\n","Estimated Total Size (MB): 1427.10\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ePnnyUWNqKAJ","colab":{},"executionInfo":{"status":"ok","timestamp":1593608605878,"user_tz":240,"elapsed":44659,"user":{"displayName":"Robert312 SpringboardDataScience","photoUrl":"","userId":"10605656056949109058"}}},"source":["learning_rate = 1e-4\n","num_epochs = 20\n","# torch.set_num_threads(1)\n","\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(net.parameters(), lr=learning_rate)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UHfot0R2qKAL","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"error","timestamp":1593620025334,"user_tz":240,"elapsed":11464113,"user":{"displayName":"Robert312 SpringboardDataScience","photoUrl":"","userId":"10605656056949109058"}},"outputId":"373ff383-9814-4285-ab60-02ef73f24f62"},"source":["train_accuracy_index = []\n","train_acc, train_total, train_correct = 0, 0, 0\n","val_accuracy_index = []\n","val_acc, val_total, val_correct = 0, 0, 0\n","test_accuracy_index = []\n","test_acc, test_total, test_correct = 0, 0, 0\n","losses_index = []\n","for epoch in range(num_epochs):  # loop over the dataset multiple times\n","    start_time = datetime.now()\n","    net.train()\n","    running_loss = 0.0\n","    epoch_loss = 0\n","    for i, data in enumerate(train_loader, 0):\n","        # get the inputs\n","        inputs, labels = data['img'], data['labels']\n","        # move data to device GPU OR CPU\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        \n","        #Get Training Accuracty\n","        # We are using BCEWithLogitsLoss for out loss\n","        # In this loss funciton, each label gets the sigmoid (inverse of Logit) before the CE loss\n","        # So our model outputs the raw values on the last FC layer\n","        # This means we have to apply sigmoid to our outputs to squash them between 0 and 1\n","        # We then take values >= .5 as Positive and < .5 as Negative\n","        predicted = outputs.data\n","        predicted = torch.sigmoid(predicted) \n","        predicted[predicted >= 0.5] = 1 # assign 1 label to those with less than 0.5\n","        predicted[predicted < 0.5] = 0 # assign 0 label to those with less than 0.5\n","        train_batch_size, train_label_count = labels.shape\n","        train_acc = float((predicted == labels).sum()) / float((train_batch_size * train_label_count))\n","        train_accuracy_index.append(train_acc)\n","\n","        #loss, back prop and update params\n","        loss = criterion(outputs, labels)#.float())\n","        loss.backward()\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","\n","    epoch_loss = epoch_loss / len(train_loader)\n","    training_time_elapsed = datetime.now() - start_time\n","    losses_index.append(epoch_loss)\n","    \n","    start_time = datetime.now()\n","\n","    # Validation set\n","    net.eval()\n","    with torch.no_grad():\n","      for data in val_loader:\n","          inputs, labels = data['img'], data['labels']\n","          inputs, labels = inputs.to(device), labels.to(device)\n","          outputs = net(inputs)\n","          predicted = outputs.data\n","          predicted = torch.sigmoid(predicted) \n","          predicted[predicted >= 0.5] = 1 \n","          predicted[predicted < 0.5] = 0 \n","          val_batch_size, val_label_count = labels.shape\n","          val_acc = float((predicted == labels).sum()) / float((val_batch_size * val_label_count))\n","          val_accuracy_index.append(val_acc)\n","   \n","    validation_time_elapsed = datetime.now() - start_time\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], \\\n","          Epoch Loss: {epoch_loss:.4f} \\\n","          Training Accuracy: {train_acc:.4f} - (Training time={training_time_elapsed}) \\\n","          Validation Accuracy: {val_acc:.4f} - (Validation time={validation_time_elapsed})')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Epoch [1/20],           Epoch Loss: 0.3550           Training Accuracy: 0.8333 - (Training time=1:40:15.795177)           Validation Accuracy: 0.9667 - (Validation time=0:18:19.440595)\n","Epoch [2/20],           Epoch Loss: 0.3342           Training Accuracy: 0.8056 - (Training time=0:10:42.220812)           Validation Accuracy: 0.9667 - (Validation time=0:01:05.557131)\n","Epoch [3/20],           Epoch Loss: 0.3293           Training Accuracy: 0.8611 - (Training time=0:10:42.381788)           Validation Accuracy: 0.9833 - (Validation time=0:01:05.710860)\n","Epoch [4/20],           Epoch Loss: 0.3263           Training Accuracy: 0.7778 - (Training time=0:10:41.734052)           Validation Accuracy: 0.9833 - (Validation time=0:01:05.654964)\n","Epoch [5/20],           Epoch Loss: 0.3235           Training Accuracy: 0.8333 - (Training time=0:10:41.270935)           Validation Accuracy: 1.0000 - (Validation time=0:01:05.714374)\n","Epoch [6/20],           Epoch Loss: 0.3222           Training Accuracy: 0.8611 - (Training time=0:10:40.888194)           Validation Accuracy: 0.9833 - (Validation time=0:01:05.079586)\n","Epoch [7/20],           Epoch Loss: 0.3207           Training Accuracy: 0.8611 - (Training time=0:10:40.365648)           Validation Accuracy: 0.9833 - (Validation time=0:01:06.575662)\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-6553c5c81c0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}