{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18140,
     "status": "ok",
     "timestamp": 1593608579322,
     "user": {
      "displayName": "Robert312 SpringboardDataScience",
      "photoUrl": "",
      "userId": "10605656056949109058"
     },
     "user_tz": 240
    },
    "id": "Krw97nCMqJ_-",
    "outputId": "923458ae-3b49-4d9c-af99-310a3d1d8f38"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os, os.path\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd() ,'/modules'))\n",
    "root_path = \"C:/git/Springboard-Public/Capstone Project 2/\"\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    root_path = \"/content/drive/My Drive/Capstone Project 2/\"\n",
    "\n",
    "print('Current Working Dir: ', os.getcwd())\n",
    "print('Root Path: ', root_path)\n",
    "\n",
    "# We need to set the working directory since we are using relative paths from various locations\n",
    "if os.getcwd() != root_path:\n",
    "  os.chdir(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25389,
     "status": "ok",
     "timestamp": 1593608586582,
     "user": {
      "displayName": "Robert312 SpringboardDataScience",
      "photoUrl": "",
      "userId": "10605656056949109058"
     },
     "user_tz": 240
    },
    "id": "A8Bb_-Y-qKAB",
    "outputId": "0a18eeb3-4c8b-4952-80bf-965e9c7e73eb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from modules.lib.ChextXRayImages import *\n",
    "from modules.models.CustomPneumonia import CustomPneumoniaNN\n",
    "\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25382,
     "status": "ok",
     "timestamp": 1593608586583,
     "user": {
      "displayName": "Robert312 SpringboardDataScience",
      "photoUrl": "",
      "userId": "10605656056949109058"
     },
     "user_tz": 240
    },
    "id": "SBlzQJJIqKAD",
    "outputId": "aa6e57c0-e47a-4548-e676-ab588aa2f635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on device=cuda\n"
     ]
    }
   ],
   "source": [
    "force_cpu = True\n",
    "device = torch.device('cuda' if ~force_cpu and torch.cuda.is_available() else 'cpu')\n",
    "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "print(f'Working on device={device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34055,
     "status": "ok",
     "timestamp": 1593608595264,
     "user": {
      "displayName": "Robert312 SpringboardDataScience",
      "photoUrl": "",
      "userId": "10605656056949109058"
     },
     "user_tz": 240
    },
    "id": "Pihx9dmDqKAH",
    "outputId": "3e36e4c4-2d3f-42ff-f0e7-af69f9a98ca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Batches: 16,035\n",
      "Number of Validation Batches: 3,965\n",
      "Number of Training Images: 16,035\n",
      "Number of Validation Images: 3,965\n"
     ]
    }
   ],
   "source": [
    "loaders = Loaders()\n",
    "batch_size=1\n",
    "val_percent=0.20\n",
    "number_images = 20000\n",
    "train_loader, val_loader = loaders.getDataTrainValidateLoaders(batch_size=batch_size, \n",
    "                                                                        val_percent=val_percent, \n",
    "                                                                        n_random_rows=number_images)\n",
    "print(f'Number of Training Batches: {len(train_loader):,}')\n",
    "print(f'Number of Validation Batches: {len(val_loader):,}')\n",
    "print(f'Number of Training Images: {len(train_loader) * batch_size:,}')\n",
    "print(f'Number of Validation Images: {len(val_loader) * batch_size:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44661,
     "status": "ok",
     "timestamp": 1593608605877,
     "user": {
      "displayName": "Robert312 SpringboardDataScience",
      "photoUrl": "",
      "userId": "10605656056949109058"
     },
     "user_tz": 240
    },
    "id": "oal5V5NeqKAG",
    "outputId": "d1303695-d7e9-4383-fccf-9e32f0b48060"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1        [-1, 512, 320, 320]          13,312\n",
      "       BatchNorm2d-2        [-1, 512, 320, 320]           1,024\n",
      "         MaxPool2d-3        [-1, 512, 160, 160]               0\n",
      "            Conv2d-4        [-1, 256, 160, 160]       1,179,904\n",
      "       BatchNorm2d-5        [-1, 256, 160, 160]             512\n",
      "         MaxPool2d-6          [-1, 256, 80, 80]               0\n",
      "            Conv2d-7           [-1, 64, 80, 80]         147,520\n",
      "       BatchNorm2d-8           [-1, 64, 80, 80]             128\n",
      "         MaxPool2d-9           [-1, 64, 40, 40]               0\n",
      "           Linear-10                 [-1, 1024]     104,858,624\n",
      "          Dropout-11                 [-1, 1024]               0\n",
      "           Linear-12                  [-1, 512]         524,800\n",
      "          Dropout-13                  [-1, 512]               0\n",
      "           Linear-14                   [-1, 12]           6,156\n",
      "CustomPneumoniaNN-15                   [-1, 12]               0\n",
      "================================================================\n",
      "Total params: 106,731,980\n",
      "Trainable params: 106,731,980\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.39\n",
      "Forward/backward pass size (MB): 1019.55\n",
      "Params size (MB): 407.15\n",
      "Estimated Total Size (MB): 1427.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net = CustomPneumoniaNN()\n",
    "\n",
    "net = nn.DataParallel(net)\n",
    "net.to(device)\n",
    "\n",
    "summary(net, (1, 320, 320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44659,
     "status": "ok",
     "timestamp": 1593608605878,
     "user": {
      "displayName": "Robert312 SpringboardDataScience",
      "photoUrl": "",
      "userId": "10605656056949109058"
     },
     "user_tz": 240
    },
    "id": "ePnnyUWNqKAJ"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "num_epochs = 20\n",
    "# torch.set_num_threads(1)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11464113,
     "status": "error",
     "timestamp": 1593620025334,
     "user": {
      "displayName": "Robert312 SpringboardDataScience",
      "photoUrl": "",
      "userId": "10605656056949109058"
     },
     "user_tz": 240
    },
    "id": "UHfot0R2qKAL",
    "outputId": "373ff383-9814-4285-ab60-02ef73f24f62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20],           Epoch Loss: 0.3557           Training Accuracy: 1.0000 - (Training time=0:21:41.189031)           Validation Accuracy: 0.9167 - (Validation time=0:01:10.687887)\n",
      "Epoch [2/20],           Epoch Loss: 0.3356           Training Accuracy: 0.9167 - (Training time=0:20:48.920123)           Validation Accuracy: 0.9167 - (Validation time=0:01:06.115091)\n",
      "Epoch [3/20],           Epoch Loss: 0.3289           Training Accuracy: 0.6667 - (Training time=0:20:49.977380)           Validation Accuracy: 0.9167 - (Validation time=0:01:06.188837)\n",
      "Epoch [4/20],           Epoch Loss: 0.3233           Training Accuracy: 0.8333 - (Training time=0:20:39.770692)           Validation Accuracy: 0.9167 - (Validation time=0:01:02.512758)\n",
      "Epoch [5/20],           Epoch Loss: 0.3185           Training Accuracy: 0.9167 - (Training time=0:20:27.413671)           Validation Accuracy: 0.8333 - (Validation time=0:01:06.193880)\n",
      "Epoch [6/20],           Epoch Loss: 0.3157           Training Accuracy: 1.0000 - (Training time=0:20:50.394209)           Validation Accuracy: 0.9167 - (Validation time=0:01:06.153987)\n",
      "Epoch [7/20],           Epoch Loss: 0.3137           Training Accuracy: 0.5833 - (Training time=0:20:50.904843)           Validation Accuracy: 0.9167 - (Validation time=0:01:06.089159)\n",
      "Epoch [8/20],           Epoch Loss: 0.3122           Training Accuracy: 0.8333 - (Training time=0:20:50.272535)           Validation Accuracy: 0.8333 - (Validation time=0:01:06.083176)\n",
      "Epoch [9/20],           Epoch Loss: 0.3117           Training Accuracy: 0.7500 - (Training time=0:20:12.829725)           Validation Accuracy: 0.9167 - (Validation time=0:01:06.202855)\n",
      "Epoch [10/20],           Epoch Loss: 0.3103           Training Accuracy: 1.0000 - (Training time=0:20:50.288491)           Validation Accuracy: 0.8333 - (Validation time=0:01:06.080184)\n",
      "Epoch [11/20],           Epoch Loss: 0.3102           Training Accuracy: 0.8333 - (Training time=0:20:50.758272)           Validation Accuracy: 0.9167 - (Validation time=0:01:06.166914)\n",
      "Epoch [12/20],           Epoch Loss: 0.3094           Training Accuracy: 0.9167 - (Training time=0:20:31.101832)           Validation Accuracy: 0.9167 - (Validation time=0:01:02.580549)\n",
      "Epoch [13/20],           Epoch Loss: 0.3090           Training Accuracy: 1.0000 - (Training time=0:20:35.921935)           Validation Accuracy: 0.8333 - (Validation time=0:01:06.211830)\n",
      "Epoch [14/20],           Epoch Loss: 0.3090           Training Accuracy: 0.8333 - (Training time=0:20:51.562090)           Validation Accuracy: 0.9167 - (Validation time=0:01:06.155975)\n",
      "Epoch [15/20],           Epoch Loss: 0.3080           Training Accuracy: 0.8333 - (Training time=0:20:51.501247)           Validation Accuracy: 0.8333 - (Validation time=0:01:06.178920)\n",
      "Epoch [16/20],           Epoch Loss: 0.3087           Training Accuracy: 0.8333 - (Training time=0:20:15.813739)           Validation Accuracy: 0.9167 - (Validation time=0:01:02.546638)\n",
      "Epoch [17/20],           Epoch Loss: 0.3078           Training Accuracy: 1.0000 - (Training time=0:20:50.425126)           Validation Accuracy: 0.8333 - (Validation time=0:01:06.233774)\n",
      "Epoch [18/20],           Epoch Loss: 0.3073           Training Accuracy: 1.0000 - (Training time=0:20:50.934764)           Validation Accuracy: 0.9167 - (Validation time=0:01:06.112096)\n",
      "Epoch [19/20],           Epoch Loss: 0.3074           Training Accuracy: 0.9167 - (Training time=0:20:13.092024)           Validation Accuracy: 0.9167 - (Validation time=0:01:06.235766)\n",
      "Epoch [20/20],           Epoch Loss: 0.3075           Training Accuracy: 0.9167 - (Training time=0:20:50.487002)           Validation Accuracy: 0.9167 - (Validation time=0:01:06.281603)\n"
     ]
    }
   ],
   "source": [
    "train_accuracy_index = []\n",
    "train_acc, train_total, train_correct = 0, 0, 0\n",
    "val_accuracy_index = []\n",
    "val_acc, val_total, val_correct = 0, 0, 0\n",
    "test_accuracy_index = []\n",
    "test_acc, test_total, test_correct = 0, 0, 0\n",
    "losses_index = []\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    start_time = datetime.now()\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    epoch_loss = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        ids, inputs, labels = data['id'], data['img'], data['labels']\n",
    "        # move data to device GPU OR CPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        #Get Training Accuracty\n",
    "        # We are using BCEWithLogitsLoss for out loss\n",
    "        # In this loss funciton, each label gets the sigmoid (inverse of Logit) before the CE loss\n",
    "        # So our model outputs the raw values on the last FC layer\n",
    "        # This means we have to apply sigmoid to our outputs to squash them between 0 and 1\n",
    "        # We then take values >= .5 as Positive and < .5 as Negative\n",
    "        predicted = outputs.data\n",
    "        predicted = torch.sigmoid(predicted) \n",
    "        predicted[predicted >= 0.5] = 1 # assign 1 label to those with less than 0.5\n",
    "        predicted[predicted < 0.5] = 0 # assign 0 label to those with less than 0.5\n",
    "        train_batch_size, train_label_count = labels.shape\n",
    "        train_acc = float((predicted == labels).sum()) / float((train_batch_size * train_label_count))\n",
    "        train_accuracy_index.append(train_acc)\n",
    "\n",
    "        #loss, back prop and update params\n",
    "        loss = criterion(outputs, labels)#.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss = epoch_loss / len(train_loader)\n",
    "    training_time_elapsed = datetime.now() - start_time\n",
    "    losses_index.append(epoch_loss)\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "\n",
    "    # Validation set\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "      for data in val_loader:\n",
    "          inputs, labels = data['img'], data['labels']\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "          outputs = net(inputs)\n",
    "          predicted = outputs.data\n",
    "          predicted = torch.sigmoid(predicted) \n",
    "          predicted[predicted >= 0.5] = 1 \n",
    "          predicted[predicted < 0.5] = 0 \n",
    "          val_batch_size, val_label_count = labels.shape\n",
    "          val_acc = float((predicted == labels).sum()) / float((val_batch_size * val_label_count))\n",
    "          val_accuracy_index.append(val_acc)\n",
    "   \n",
    "    validation_time_elapsed = datetime.now() - start_time\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], \\\n",
    "          Epoch Loss: {epoch_loss:.4f} \\\n",
    "          Training Accuracy: {train_acc:.4f} - (Training time={training_time_elapsed}) \\\n",
    "          Validation Accuracy: {val_acc:.4f} - (Validation time={validation_time_elapsed})')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CustomPneumonia.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
