{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Dir:  C:\\git\\Springboard-Public\\Capstone Project 2\\notebooks\\Support Notebooks for Modules\n",
      "Root Path:  C:/git/Springboard-Public/Capstone Project 2/\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os, os.path\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd() ,'/modules'))\n",
    "root_path = \"C:/git/Springboard-Public/Capstone Project 2/\"\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    root_path = \"/content/drive/My Drive/Capstone Project 2/\"\n",
    "\n",
    "print('Current Working Dir: ', os.getcwd())\n",
    "print('Root Path: ', root_path)\n",
    "\n",
    "# We need to set the working directory since we are using relative paths from various locations\n",
    "if os.getcwd() != root_path:\n",
    "  os.chdir(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import os, os.path\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "from modules.lib.ChextXRayImages import CleanMetaData, Dataset, Loaders\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get DataFrame from our Prep class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanMetaData = CleanMetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>StudyID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex_Male</th>\n",
       "      <th>Sex_Unknown</th>\n",
       "      <th>Orientation_PA</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>Image_Path</th>\n",
       "      <th>Hierarchical_Path</th>\n",
       "      <th>Enlarged_Cardiomediastinum</th>\n",
       "      <th>...</th>\n",
       "      <th>Lung_Opacity</th>\n",
       "      <th>Lung_Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural_Effusion</th>\n",
       "      <th>Pleural_Other</th>\n",
       "      <th>Fracture</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>data/raw/train/patient00001/study1/view1_front...</td>\n",
       "      <td>data/d0/d1/i0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data/raw/train/patient00002/study2/view1_front...</td>\n",
       "      <td>data/d1/d2/i1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data/raw/train/patient00002/study1/view1_front...</td>\n",
       "      <td>data/d2/d2/i2.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data/raw/train/patient00003/study1/view1_front...</td>\n",
       "      <td>data/d4/d3/i4.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data/raw/train/patient00004/study1/view1_front...</td>\n",
       "      <td>data/d5/d4/i5.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223409</td>\n",
       "      <td>64537</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data/raw/train/patient64537/study2/view1_front...</td>\n",
       "      <td>data/d9/d37/i223409.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223410</td>\n",
       "      <td>64537</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data/raw/train/patient64537/study1/view1_front...</td>\n",
       "      <td>data/d10/d37/i223410.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223411</td>\n",
       "      <td>64538</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data/raw/train/patient64538/study1/view1_front...</td>\n",
       "      <td>data/d11/d38/i223411.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223412</td>\n",
       "      <td>64539</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data/raw/train/patient64539/study1/view1_front...</td>\n",
       "      <td>data/d12/d39/i223412.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223413</td>\n",
       "      <td>64540</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data/raw/train/patient64540/study1/view1_front...</td>\n",
       "      <td>data/d13/d40/i223413.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131748 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PatientID  StudyID  Age  Sex_Male  Sex_Unknown  Orientation_PA  \\\n",
       "ImageID                                                                   \n",
       "0                1        1   68         0            0               0   \n",
       "1                2        2   87         0            0               0   \n",
       "2                2        1   83         0            0               0   \n",
       "4                3        1   41         1            0               0   \n",
       "5                4        1   20         0            0               1   \n",
       "...            ...      ...  ...       ...          ...             ...   \n",
       "223409       64537        2   59         1            0               0   \n",
       "223410       64537        1   59         1            0               0   \n",
       "223411       64538        1    0         0            0               0   \n",
       "223412       64539        1    0         0            0               0   \n",
       "223413       64540        1    0         0            0               0   \n",
       "\n",
       "         Support Devices                                         Image_Path  \\\n",
       "ImageID                                                                       \n",
       "0                    1.0  data/raw/train/patient00001/study1/view1_front...   \n",
       "1                    0.0  data/raw/train/patient00002/study2/view1_front...   \n",
       "2                    0.0  data/raw/train/patient00002/study1/view1_front...   \n",
       "4                    0.0  data/raw/train/patient00003/study1/view1_front...   \n",
       "5                    0.0  data/raw/train/patient00004/study1/view1_front...   \n",
       "...                  ...                                                ...   \n",
       "223409               0.0  data/raw/train/patient64537/study2/view1_front...   \n",
       "223410               0.0  data/raw/train/patient64537/study1/view1_front...   \n",
       "223411               0.0  data/raw/train/patient64538/study1/view1_front...   \n",
       "223412               0.0  data/raw/train/patient64539/study1/view1_front...   \n",
       "223413               0.0  data/raw/train/patient64540/study1/view1_front...   \n",
       "\n",
       "                Hierarchical_Path  Enlarged_Cardiomediastinum  ...  \\\n",
       "ImageID                                                        ...   \n",
       "0               data/d0/d1/i0.jpg                           0  ...   \n",
       "1               data/d1/d2/i1.jpg                           0  ...   \n",
       "2               data/d2/d2/i2.jpg                           0  ...   \n",
       "4               data/d4/d3/i4.jpg                           0  ...   \n",
       "5               data/d5/d4/i5.jpg                           0  ...   \n",
       "...                           ...                         ...  ...   \n",
       "223409    data/d9/d37/i223409.jpg                           0  ...   \n",
       "223410   data/d10/d37/i223410.jpg                           0  ...   \n",
       "223411   data/d11/d38/i223411.jpg                           0  ...   \n",
       "223412   data/d12/d39/i223412.jpg                           0  ...   \n",
       "223413   data/d13/d40/i223413.jpg                           0  ...   \n",
       "\n",
       "         Lung_Opacity  Lung_Lesion  Edema  Consolidation  Pneumonia  \\\n",
       "ImageID                                                               \n",
       "0                   0            0      0              0          0   \n",
       "1                   1            0      0              0          0   \n",
       "2                   1            0      0              0          0   \n",
       "4                   0            0      1              0          0   \n",
       "5                   0            0      0              0          0   \n",
       "...               ...          ...    ...            ...        ...   \n",
       "223409              0            0      0              0          0   \n",
       "223410              0            0      0              0          0   \n",
       "223411              0            0      0              0          0   \n",
       "223412              1            0      0              0          0   \n",
       "223413              0            0      0              0          0   \n",
       "\n",
       "         Atelectasis  Pneumothorax  Pleural_Effusion  Pleural_Other  Fracture  \n",
       "ImageID                                                                        \n",
       "0                  0             0                 0              0         0  \n",
       "1                  0             0                 0              0         1  \n",
       "2                  0             0                 0              0         1  \n",
       "4                  0             0                 0              0         0  \n",
       "5                  0             0                 0              0         0  \n",
       "...              ...           ...               ...            ...       ...  \n",
       "223409             0             0                 1              0         0  \n",
       "223410             0             0                 0              0         0  \n",
       "223411             0             0                 0              0         0  \n",
       "223412             1             0                 0              0         0  \n",
       "223413             0             0                 0              0         0  \n",
       "\n",
       "[131748 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cleanMetaData.getCleanDF()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build our own DataSet class\n",
    "\n",
    "We need to do this so that the DS will hold the multiple labels\n",
    "\n",
    "In the constructor, we walk every row in the DataFrame from above and hold all the label values in a list for each feature.\n",
    "\n",
    "The index of these lists match the image.  The iterator returns key value pairs.  The first is the image tensor (converted to tensor via the transform).  The other keys map to the 12 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXRayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "\n",
    "        # initialize the arrays to store the ground truth labels and paths to the images\n",
    "        self.data = []\n",
    "        self.Enlarged_Cardiomediastinum = []\n",
    "        self.Cardiomegaly = []\n",
    "        self.Lung_Opacity = []\n",
    "        self.Lung_Lesion = []\n",
    "        self.Edema = []\n",
    "        self.Consolidation = []\n",
    "        self.Pneumonia = []\n",
    "        self.Atelectasis = []\n",
    "        self.Pneumothorax = []\n",
    "        self.Pleural_Effusion = []\n",
    "        self.Pleural_Other = []\n",
    "        self.Fracture = []\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.to_tensor = ToTensor()\n",
    "        self.to_pil = ToPILImage()\n",
    "\n",
    "        # Load the image and lables for each row in the DataFrame\n",
    "        for _, row in df.iterrows():\n",
    "            self.data.append(row.Image_Path)\n",
    "            self.Enlarged_Cardiomediastinum.append(row['Enlarged_Cardiomediastinum'])\n",
    "            self.Cardiomegaly.append(row['Cardiomegaly'])\n",
    "            self.Lung_Opacity.append(row['Lung_Opacity'])\n",
    "            self.Lung_Lesion.append(row['Lung_Lesion'])\n",
    "            self.Edema.append(row['Edema'])\n",
    "            self.Consolidation.append(row['Consolidation'])\n",
    "            self.Pneumonia.append(row['Pneumonia'])\n",
    "            self.Atelectasis.append(row['Atelectasis'])\n",
    "            self.Pneumothorax.append(row['Pneumothorax'])\n",
    "            self.Pleural_Effusion.append(row['Pleural_Effusion'])\n",
    "            self.Pleural_Other.append(row['Pleural_Other'])\n",
    "            self.Fracture.append(row['Fracture'])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        # take the data sample by its index\n",
    "        img_path = self.data[idx]\n",
    "\n",
    "        # read image\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # apply the image augmentations if needed\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # return the image and all the associated labels\n",
    "        result = {\n",
    "            'img': img,\n",
    "            'labels': {\n",
    "                        'Enlarged_Cardiomediastinum': self.Enlarged_Cardiomediastinum[idx],\n",
    "                        'Cardiomegaly': self.Cardiomegaly[idx],\n",
    "                        'Lung_Opacity': self.Lung_Opacity[idx],\n",
    "                        'Lung_Lesion': self.Lung_Lesion[idx],\n",
    "                        'Edema': self.Edema[idx],\n",
    "                        'Consolidation': self.Consolidation[idx],\n",
    "                        'Pneumonia': self.Pneumonia[idx],\n",
    "                        'Atelectasis': self.Atelectasis[idx],\n",
    "                        'Pneumothorax': self.Pneumothorax[idx],\n",
    "                        'Pleural_Effusion': self.Pleural_Effusion[idx],\n",
    "                        'Pleural_Other': self.Pleural_Other[idx],\n",
    "                        'Fracture': self.Fracture[idx]\n",
    "                    }\n",
    "        }\n",
    "        return result            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The dataset class makes it easy to find counts\n",
    "\n",
    "We will create a temp data set for now without the resize or Normalization transformations since we have yet to look at these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Negative: 0.0\n",
      "  Positive: 44,734\n",
      "No Finding: 0\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.Grayscale(1),\n",
    "                              transforms.ToTensor()])\n",
    "tempDS = ChestXRayDataset(df, transform=transform)\n",
    "\n",
    "print(f'  Negative: {np.sum([-i for i in tempDS.Pleural_Effusion if i == -1]):,}\\n' +\n",
    "      f'  Positive: {np.sum([i for i in tempDS.Pleural_Effusion if i == 1]):,}\\n' + \n",
    "      f'No Finding: {np.sum([i for i in tempDS.Pleural_Effusion if i == 0]):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at the shapes of the images\n",
    "\n",
    "We will just sampe every 100th image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = cleanMetaData.imageFolderPath()\n",
    "image_widths = []\n",
    "image_heights = []\n",
    "image_pixel_counts = []\n",
    "counter=0\n",
    "\n",
    "for dirpath, _, filenames in os.walk(image_folder):\n",
    "    for path_image in filenames:\n",
    "        counter+=1\n",
    "        if counter % 100 == 0:\n",
    "            image = os.path.join(dirpath, path_image)\n",
    "            with Image.open(image) as img:\n",
    "                width, heigth = img.size\n",
    "                image_widths.append(width)\n",
    "                image_heights.append(heigth)\n",
    "                image_pixel_counts.append(width * heigth)\n",
    "\n",
    "isdf = pd.DataFrame({'Width': image_widths, 'Height': image_heights, 'Pixels':image_pixel_counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1822</td>\n",
       "      <td>483</td>\n",
       "      <td>320</td>\n",
       "      <td>154560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2161</td>\n",
       "      <td>439</td>\n",
       "      <td>320</td>\n",
       "      <td>140480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1863</td>\n",
       "      <td>439</td>\n",
       "      <td>320</td>\n",
       "      <td>140480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>426</td>\n",
       "      <td>320</td>\n",
       "      <td>136320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>418</td>\n",
       "      <td>320</td>\n",
       "      <td>133760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>320</td>\n",
       "      <td>369</td>\n",
       "      <td>118080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>661</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "      <td>102400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "      <td>102400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>320</td>\n",
       "      <td>333</td>\n",
       "      <td>106560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>903</td>\n",
       "      <td>320</td>\n",
       "      <td>390</td>\n",
       "      <td>124800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2234 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Width  Height  Pixels\n",
       "1822    483     320  154560\n",
       "2161    439     320  140480\n",
       "1863    439     320  140480\n",
       "293     426     320  136320\n",
       "760     418     320  133760\n",
       "...     ...     ...     ...\n",
       "253     320     369  118080\n",
       "661     320     320  102400\n",
       "660     320     320  102400\n",
       "1330    320     333  106560\n",
       "903     320     390  124800\n",
       "\n",
       "[2234 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min/Max Height = 320/483\n",
      "         Min/Max Width = 320/461\n",
      "         Min/Max Pixels = 102400/154560\n"
     ]
    }
   ],
   "source": [
    "display(isdf.sort_values('Width', ascending=False))\n",
    "print(f'Min/Max Height = {isdf.Width.min()}/{isdf.Width.max()}\\n \\\n",
    "        Min/Max Width = {isdf.Height.min()}/{isdf.Height.max()}\\n \\\n",
    "        Min/Max Pixels = {isdf.Pixels.min()}/{isdf.Pixels.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like most images are around four hundred by 320. \n",
    "\n",
    "Some are protrait and some are landscape\n",
    "\n",
    "So let's pick the resize transformation to be 320X320\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hight,width = 320, 320\n",
    "transform = transforms.Compose(\n",
    "                              [transforms.Resize(size=(hight,width), interpolation=2),\n",
    "                              transforms.Grayscale(1),\n",
    "                              transforms.ToTensor()])\n",
    "chestXRayDataset = Dataset(df, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we will build a data loader to evaluate the mean and SD of the pixels\n",
    "\n",
    "We will randomly choose 2,500 images for this.  To do this, we will use the Subset object from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = torch.utils.data.Subset(chestXRayDataset, np.random.choice(len(chestXRayDataset), 2500, replace=False))\n",
    "loader = torch.utils.data.DataLoader(dss, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Pixel Value: 0.5064167\n",
      "SD:0.16673872\n"
     ]
    }
   ],
   "source": [
    "pixel_mean = 0.5064167\n",
    "pixel_sd = 0.16673872\n",
    "\n",
    "if pixel_mean == 0:\n",
    "    image_count = 0\n",
    "    fst_moment = torch.empty(1)\n",
    "    snd_moment = torch.empty(1)\n",
    "\n",
    "    for batch in loader:\n",
    "      images = batch['img']\n",
    "      b, c, h, w = images.shape\n",
    "      nb_pixels = b * h * w\n",
    "      sum_ = torch.sum(images, dim=[0, 2, 3])\n",
    "      sum_of_square = torch.sum(images ** 2, dim=[0, 2, 3])\n",
    "      fst_moment = (image_count * fst_moment + sum_) / (image_count + nb_pixels)\n",
    "      snd_moment = (image_count * snd_moment + sum_of_square) / (image_count + nb_pixels)\n",
    "\n",
    "      image_count += nb_pixels\n",
    "\n",
    "    pixel_mean = fst_moment.numpy()  \n",
    "    pixel_sd = torch.sqrt((snd_moment - fst_moment) ** 2).numpy()\n",
    "\n",
    "print(f'Mean Pixel Value: {pixel_mean}\\nSD:{pixel_sd}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have both the size and statistics for the images\n",
    "\n",
    "So we can build the final transformation and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "                              [transforms.Resize(size=(hight,width), interpolation=2),\n",
    "                              transforms.Grayscale(1),\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((pixel_mean,), (pixel_sd,))])\n",
    "chestXRayDataset = Dataset(df, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset Loaders classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get single loader for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Batches: 2,059\n",
      "Number of Images: 131,776\n"
     ]
    }
   ],
   "source": [
    "loader = Loaders().getDataLoader()\n",
    "print(f'Number of Batches: {len(loader):,}')\n",
    "print(f'Number of Images: {len(loader) * 64:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get single load for 500 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Batches: 32\n",
      "Number of Images: 512\n"
     ]
    }
   ],
   "source": [
    "batch_size=16\n",
    "loader = Loaders().getDataLoader(batch_size=batch_size, n_random_rows=512)\n",
    "print(f'Number of Batches: {len(loader):,}')\n",
    "print(f'Number of Images: {len(loader) * batch_size:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get train/validation loaders for 15,000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Batches: 12,729\n",
      "Number of Validation Batches: 2,271\n",
      "Number of Training Images: 12,729\n",
      "Number of Validation Images: 2,271\n"
     ]
    }
   ],
   "source": [
    "batch_size=1\n",
    "val_percent=0.15\n",
    "number_images = 15000\n",
    "train_loader, val_loader = Loaders().getDataTrainValidateLoaders(batch_size=batch_size, \n",
    "                                                                        val_percent=val_percent, \n",
    "                                                                        n_random_rows=number_images)\n",
    "print(f'Number of Training Batches: {len(train_loader):,}')\n",
    "print(f'Number of Validation Batches: {len(val_loader):,}')\n",
    "print(f'Number of Training Images: {len(train_loader) * batch_size:,}')\n",
    "print(f'Number of Validation Images: {len(val_loader) * batch_size:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaData = CleanMetaData()\n",
    "df = metaData.getCleanDF()\n",
    "missing_images = []\n",
    "missing_hierarchical_images = []\n",
    "for _, row in df.iterrows():\n",
    "    if not os.path.exists(row.Image_Path):\n",
    "      missing_images.append(row.Image_Path)\n",
    "    if not os.path.exists(row.Hierarchical_Path):\n",
    "      missing_hierarchical_images.append(row.Hierarchical_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_images), len(missing_hierarchical_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
