{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Dir:  C:\\git\\Springboard-Public\\Capstone Project 2\\notebooks\\Support Notebooks for Modules\n",
      "Root Path:  C:/git/Springboard-Public/Capstone Project 2/\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os, os.path\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd() ,'/modules'))\n",
    "root_path = \"C:/git/Springboard-Public/Capstone Project 2/\"\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    root_path = \"/content/drive/My Drive/Capstone Project 2/\"\n",
    "\n",
    "print('Current Working Dir: ', os.getcwd())\n",
    "print('Root Path: ', root_path)\n",
    "\n",
    "# We need to set the working directory since we are using relative paths from various locations\n",
    "if os.getcwd() != root_path:\n",
    "  os.chdir(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from modules.lib.ChextXRayImages import *\n",
    "from modules.models.CustomPneumonia import CustomPneumoniaNN\n",
    "\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on device=cuda\n"
     ]
    }
   ],
   "source": [
    "force_cpu = True\n",
    "device = torch.device('cuda' if ~force_cpu and torch.cuda.is_available() else 'cpu')\n",
    "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "print(f'Working on device={device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Batches: 10\n",
      "Number of Validation Batches: 90\n",
      "Number of Training Images: 10\n",
      "Number of Validation Images: 90\n"
     ]
    }
   ],
   "source": [
    "loaders = Loaders()\n",
    "batch_size=1\n",
    "val_percent=0.15\n",
    "number_images = 100\n",
    "train_loader, val_loader = loaders.getDataTrainValidateLoaders(batch_size=batch_size, \n",
    "                                                                        val_percent=val_percent, \n",
    "                                                                        n_random_rows=number_images)\n",
    "print(f'Number of Training Batches: {len(train_loader):,}')\n",
    "print(f'Number of Validation Batches: {len(val_loader):,}')\n",
    "print(f'Number of Training Images: {len(train_loader) * batch_size:,}')\n",
    "print(f'Number of Validation Images: {len(val_loader) * batch_size:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)       \n",
    "        self.flattened_length_ = 1*320*320\n",
    "        self.fc1 = nn.Linear(self.flattened_length_, 12)\n",
    "       \n",
    "    def forward(self, x):    \n",
    "        x = x.view(-1, self.flattened_length_)    \n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 12]       1,228,812\n",
      "       SimpleModel-2                   [-1, 12]               0\n",
      "================================================================\n",
      "Total params: 1,228,812\n",
      "Trainable params: 1,228,812\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.39\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 4.69\n",
      "Estimated Total Size (MB): 5.08\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net = SimpleModel()\n",
    "\n",
    "net = nn.DataParallel(net)\n",
    "net.to(device)\n",
    "\n",
    "summary(net, (1, 320, 320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "num_epochs = 1\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)#, weight_decay=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12])\n",
      "torch.Size([1, 1, 320, 320])\n",
      "torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_loader))\n",
    "inputs, labels = data['img'], data['labels']\n",
    "\n",
    "print(labels.shape)\n",
    "\n",
    "# move data to device GPU OR CPU\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = net(inputs)\n",
    "print(inputs.shape)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train()\n",
    "for i, data in enumerate(train_loader, 0):\n",
    "    # get the inputs\n",
    "    inputs, labels = data['img'], data['labels']\n",
    "    \n",
    "    # move data to device GPU OR CPU\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    #loss, back prop and update params\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1],           Epoch Loss: 2.1868           Training Accuracy: 0.0000            Validation Accuracy: 1.0444 - (time=0:00:00.068815)\n"
     ]
    }
   ],
   "source": [
    "train_accuracy_index = []\n",
    "train_acc, train_total, train_correct = 0, 0, 0\n",
    "val_accuracy_index = []\n",
    "val_acc, val_total, val_correct = 0, 0, 0\n",
    "test_accuracy_index = []\n",
    "test_acc, test_total, test_correct = 0, 0, 0\n",
    "losses_index = []\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    start_time = datetime.now()\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    epoch_loss = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data['img'], data['labels']\n",
    "        # move data to device GPU OR CPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        #Get Training Accuracty\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        train_acc = train_correct/train_total\n",
    "        train_accuracy_index.append(train_acc)\n",
    "\n",
    "        #loss, back prop and update params\n",
    "        loss = criterion(outputs, labels)#.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss = epoch_loss / len(train_loader)\n",
    "    time_elapsed = datetime.now() - start_time\n",
    "    losses_index.append(epoch_loss)\n",
    "    \n",
    "    # Validation set\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "      for data in val_loader:\n",
    "          inputs, labels = data['img'], data['labels']\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "          outputs = net(inputs)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          val_total += labels.size(0)\n",
    "          val_correct += (predicted == labels).sum().item()\n",
    "          val_acc = val_correct/val_total\n",
    "      val_accuracy_index.append(val_acc)\n",
    "   \n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], \\\n",
    "          Epoch Loss: {epoch_loss:.4f} \\\n",
    "          Training Accuracy: {train_acc:.4f}  \\\n",
    "          Validation Accuracy: {val_acc:.4f} - (time={time_elapsed})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
