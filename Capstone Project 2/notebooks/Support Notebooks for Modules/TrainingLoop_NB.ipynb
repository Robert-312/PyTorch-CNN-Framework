{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Dir:  C:\\git\\Springboard-Public\\Capstone Project 2\\notebooks\\Support Notebooks for Modules\n",
      "Root Path:  C:/git/Springboard-Public/Capstone Project 2/\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os, os.path\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd() ,'/modules'))\n",
    "root_path = \"C:/git/Springboard-Public/Capstone Project 2/\"\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    root_path = \"/content/drive/My Drive/Capstone Project 2/\"\n",
    "\n",
    "print('Current Working Dir: ', os.getcwd())\n",
    "print('Root Path: ', root_path)\n",
    "\n",
    "# We need to set the working directory since we are using relative paths from various locations\n",
    "if os.getcwd() != root_path:\n",
    "  os.chdir(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from modules.lib.ChextXRayImages import *\n",
    "from modules.models.CustomPneumonia import CustomPneumoniaNN\n",
    "\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on device=cuda\n"
     ]
    }
   ],
   "source": [
    "force_cpu = True\n",
    "device = torch.device('cuda' if ~force_cpu and torch.cuda.is_available() else 'cpu')\n",
    "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "print(f'Working on device={device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\git\\Springboard-Public\\Capstone Project 2\\modules\\lib\\ChextXRayImages.py:244: UserWarning: \n",
      "Feature Imbalance Detected (train % - val %):\n",
      "   Cardiomegaly: 2.12%\n",
      "   Consolidation: 3.01%\n",
      "   Pleural_Effusion: 3.98%\n",
      "\n",
      "  self.warnFeatureImbalance(train, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Batches: 55\n",
      "Number of Validation Batches: 8\n",
      "Number of Training Images: 880\n",
      "Number of Validation Images: 128\n"
     ]
    }
   ],
   "source": [
    "loaders = Loaders()\n",
    "batch_size=16\n",
    "val_percent=0.15\n",
    "number_images = 1000\n",
    "train_loader, val_loader = loaders.getDataTrainValidateLoaders(batch_size=batch_size, \n",
    "                                                                        val_percent=val_percent, \n",
    "                                                                        n_random_rows=number_images)\n",
    "print(f'Number of Training Batches: {len(train_loader):,}')\n",
    "print(f'Number of Validation Batches: {len(val_loader):,}')\n",
    "print(f'Number of Training Images: {len(train_loader) * batch_size:,}')\n",
    "print(f'Number of Validation Images: {len(val_loader) * batch_size:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)       \n",
    "        self.flattened_length_ = 1*320*320\n",
    "        self.fc1 = nn.Linear(self.flattened_length_, 12)\n",
    "       \n",
    "    def forward(self, x):    \n",
    "        x = x.view(-1, self.flattened_length_)    \n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 12]       1,228,812\n",
      "       SimpleModel-2                   [-1, 12]               0\n",
      "================================================================\n",
      "Total params: 1,228,812\n",
      "Trainable params: 1,228,812\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.39\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 4.69\n",
      "Estimated Total Size (MB): 5.08\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net = SimpleModel()\n",
    "\n",
    "net = nn.DataParallel(net)\n",
    "net.to(device)\n",
    "\n",
    "summary(net, (1, 320, 320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ImageIDs:  [ 90069 184464  12412  13573 138960 219437  51083 221958 148671 214194\n",
      "  51529 222821 213681 118589    643 216996]\n",
      "torch.Size([16, 12])\n",
      "torch.Size([16, 1, 320, 320])\n",
      "torch.Size([16, 12])\n",
      "--------------------------------------------------\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.],\n",
      "        [1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0.]], device='cuda:0') \n",
      "\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "--------------------------------------------------\n",
      "Accurate Predictions:  tensor(112, device='cuda:0')\n",
      "Total Predictions:  192\n",
      "0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_loader))\n",
    "ImageID, inputs, labels = data['id'], data['img'], data['labels']\n",
    "\n",
    "print('Batch ImageIDs: ', ImageID.detach().numpy())\n",
    "\n",
    "print(labels.shape)\n",
    "\n",
    "# move data to device GPU OR CPU\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = net(inputs)\n",
    "print(inputs.shape)\n",
    "print(outputs.shape)\n",
    "\n",
    "print('-' * 50)\n",
    "\n",
    "predicted = outputs.data\n",
    "predicted = torch.sigmoid(predicted) \n",
    "\n",
    "predicted[predicted >= 0.5] = 1 # assign 1 label to those with less than 0.5\n",
    "predicted[predicted < 0.5] = 0 # assign 0 label to those with less than 0.5\n",
    "print(predicted, '\\n')\n",
    "print(labels)\n",
    "\n",
    "\n",
    "print('-' * 50)\n",
    "\n",
    "train_batch_size, train_label_count = labels.shape\n",
    "\n",
    "print('Accurate Predictions: ', (predicted == labels).sum())\n",
    "print('Total Predictions: ', train_batch_size * train_label_count)\n",
    "train_acc = float((predicted == labels).sum()) / float((train_batch_size * train_label_count))\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseLoaderData(data):\n",
    "    \"\"\"\n",
    "    The data loaders output a dictionary with 3 keys\n",
    "    The first 2 keys hold single values for the ImageID and the actual tensor of the image\n",
    "    The last key holds a vector of the actual 12 lables\n",
    "    \"\"\" \n",
    "    \n",
    "    ids, inputs, labels = data['id'], data['img'], data['labels']\n",
    "    # move data to device GPU OR CPU\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    return ids, inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictionsFromOutput(outputs):\n",
    "    \"\"\"\n",
    "    We are using BCEWithLogitsLoss for out loss\n",
    "    In this loss funciton, each label gets the sigmoid (inverse of Logit) before the CE loss\n",
    "    So our model outputs the raw values on the last FC layer\n",
    "    This means we have to apply sigmoid to our outputs to squash them between 0 and 1\n",
    "    We then take values >= .5 as Positive and < .5 as Negative \n",
    "    \"\"\"\n",
    "    \n",
    "    predictions = torch.sigmoid(outputs.data) \n",
    "    predictions[predictions >= 0.5] = 1 # assign 1 label to those with less than 0.5\n",
    "    predictions[predictions < 0.5] = 0 # assign 0 label to those with less than 0.5   \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updatePredictionDictionary(dictionary, ids, predictions):\n",
    "    \"\"\"\n",
    "    Keep track of predictions using the same index as our DataFrame\n",
    "    This will allow us to compare to the actual labels\n",
    "    \n",
    "    We only are taking the last prediction for each x-ray, but we could extend this later if wanted.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(ids)):\n",
    "        id = ids[i].item()    \n",
    "        dictionary[id] = [int(f.item()) for f in predictions[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOverallAccuracy(predictions, labels):\n",
    "    \"\"\"\n",
    "    Overall accuracy for multi-label classifiction will be caculated as\n",
    "    the number of correct predictions divided by the total number of predctions\n",
    "    \n",
    "    The total # of predicitons is the the # of lables times to # in the batch\n",
    "    i.e. 12 lables with a batch size of 10 = 120 predicitons\n",
    "    \n",
    "    The problem with this score is that many of the features have a very low positive rate\n",
    "    \n",
    "    This can make this score misleadingly accurate\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size, label_count = labels.shape\n",
    "    return float((predictions == labels).sum()) / float((batch_size * label_count))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processBatch(net, data, optimizer=None):\n",
    "    \"\"\"\n",
    "    Used for both training and validation.\n",
    "    Validation will not pass in the optimizer.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert output from loader\n",
    "    ids, inputs, labels = parseLoaderData(data)\n",
    "    \n",
    "    if optimizer:\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    # Convert output to predicitons\n",
    "    outputs = net(inputs)\n",
    "    predictions = getPredictionsFromOutput(outputs)\n",
    "    \n",
    "    return ids, inputs, labels, outputs, predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backProp(criterion, outputs, labels, optimizer):\n",
    "    \"\"\"\n",
    "    Get loss value from criterion\n",
    "    run backprop on the loss\n",
    "    update weights in optimizer\n",
    "    update epoch loss\n",
    "    \"\"\"\n",
    "    \n",
    "    loss = criterion(outputs, labels)#.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictionDataFrame(last_predictions, loaders):\n",
    "    result = pd.DataFrame(last_predictions).transpose()\n",
    "    result.columns = loaders.target_columns\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_index = []\n",
    "train_overall_acc, train_total, train_correct = 0, 0, 0\n",
    "val_accuracy_index = []\n",
    "val_overall_acc, val_total, val_correct = 0, 0, 0\n",
    "losses_index = []\n",
    "\n",
    "last_training_predictions = {}\n",
    "last_validation_predictions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "num_epochs = 8\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)#, weight_decay=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/8], \n",
      "          Epoch Loss: 0.9565 \n",
      "          Training Accuracy: 77.78% - (Training time=0:00:03.182484)  \n",
      "          Validation Accuracy: 75.00% - (time=0:00:03.590393)\n",
      "Epoch [2/8], \n",
      "          Epoch Loss: 0.7646 \n",
      "          Training Accuracy: 80.56% - (Training time=0:00:03.163535)  \n",
      "          Validation Accuracy: 80.00% - (time=0:00:03.574435)\n",
      "Epoch [3/8], \n",
      "          Epoch Loss: 0.7700 \n",
      "          Training Accuracy: 77.78% - (Training time=0:00:03.168521)  \n",
      "          Validation Accuracy: 82.22% - (time=0:00:03.574434)\n",
      "Epoch [4/8], \n",
      "          Epoch Loss: 0.8357 \n",
      "          Training Accuracy: 77.78% - (Training time=0:00:03.162537)  \n",
      "          Validation Accuracy: 81.11% - (time=0:00:03.581417)\n",
      "Epoch [5/8], \n",
      "          Epoch Loss: 0.8312 \n",
      "          Training Accuracy: 79.63% - (Training time=0:00:03.183481)  \n",
      "          Validation Accuracy: 71.11% - (time=0:00:03.592389)\n",
      "Epoch [6/8], \n",
      "          Epoch Loss: 0.7855 \n",
      "          Training Accuracy: 86.11% - (Training time=0:00:03.151567)  \n",
      "          Validation Accuracy: 75.56% - (time=0:00:03.557481)\n",
      "Epoch [7/8], \n",
      "          Epoch Loss: 0.7644 \n",
      "          Training Accuracy: 85.19% - (Training time=0:00:03.163537)  \n",
      "          Validation Accuracy: 73.33% - (time=0:00:03.569449)\n",
      "Epoch [8/8], \n",
      "          Epoch Loss: 0.7994 \n",
      "          Training Accuracy: 82.41% - (Training time=0:00:03.202431)  \n",
      "          Validation Accuracy: 82.78% - (time=0:00:03.604356)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    start_time = datetime.now()\n",
    "    running_loss = 0.0\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # Training\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        ids, inputs, labels, outputs, predictions = processBatch(net, data, optimizer)\n",
    "        updatePredictionDictionary(last_training_predictions, ids, predictions)\n",
    "        train_overall_acc = getOverallAccuracy(predictions, labels)\n",
    "        train_accuracy_index.append(train_overall_acc)\n",
    "        epoch_loss += backProp(criterion, outputs, labels, optimizer)\n",
    "\n",
    "    epoch_loss = epoch_loss / len(train_loader)\n",
    "    training_time_elapsed = datetime.now() - start_time\n",
    "    losses_index.append(epoch_loss)\n",
    "    \n",
    "    # Validation\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "      for data in val_loader:          \n",
    "            ids, inputs, labels, _, predictions = processBatch(net, data)\n",
    "            updatePredictionDictionary(last_validation_predictions, ids, predictions)\n",
    "            val_overall_acc = getOverallAccuracy(predictions, labels)\n",
    "            val_accuracy_index.append(val_overall_acc)\n",
    "   \n",
    "    validation_time_elapsed = datetime.now() - start_time\n",
    "    \n",
    "    # stdout Results\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], \\\n",
    "\\n          Epoch Loss: {epoch_loss:.4f} \\\n",
    "\\n          Training Accuracy: {train_overall_acc:.2%} - (Training time={training_time_elapsed})  \\\n",
    "\\n          Validation Accuracy: {val_overall_acc:.2%} - (time={validation_time_elapsed})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_predictions_df = getPredictionDataFrame(last_training_predictions, loaders)\n",
    "validation_predictions_df = getPredictionDataFrame(last_validation_predictions, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Enlarged_Cardiomediastinum    0\n",
       "Cardiomegaly                  0\n",
       "Lung_Opacity                  0\n",
       "Lung_Lesion                   0\n",
       "Edema                         0\n",
       "Consolidation                 0\n",
       "Pneumonia                     0\n",
       "Atelectasis                   0\n",
       "Pneumothorax                  0\n",
       "Pleural_Effusion              1\n",
       "Pleural_Other                 0\n",
       "Fracture                      0\n",
       "Name: 45510, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Enlarged_Cardiomediastinum    0\n",
       "Cardiomegaly                 -1\n",
       "Lung_Opacity                  0\n",
       "Lung_Lesion                   0\n",
       "Edema                         0\n",
       "Consolidation                 0\n",
       "Pneumonia                     0\n",
       "Atelectasis                   0\n",
       "Pneumothorax                  0\n",
       "Pleural_Effusion              1\n",
       "Pleural_Other                 0\n",
       "Fracture                      0\n",
       "Name: 45510, dtype: int8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(trained_predictions_df.loc[45510, :])\n",
    "display(loaders.train_df[loaders.target_columns].loc[45510, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
